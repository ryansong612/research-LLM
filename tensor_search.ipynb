{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#Read Chemistry abstract title data from desktop#\n",
    "documents = []\n",
    "with open('/Users/ryansong612/Desktop/research-LLM/output/all.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    for subject in data:\n",
    "        for article in data[subject]:\n",
    "            document = { \"subject\": subject,\n",
    "                         \"title\": article[\"title\"],\n",
    "                         \"abstract\": article[\"abstract\"]}\n",
    "            documents.append(document)\n",
    "\n",
    "#define embedding calculation function#\n",
    "def embed_sentences(sentences):\n",
    "    # Load the Universal Sentence Encoder module\n",
    "    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "    model = hub.load(module_url)\n",
    "    # Generate embeddings for the sentences\n",
    "    embeddings = model(sentences)\n",
    "    return embeddings\n",
    "\n",
    "#define similarity calculation function based on dot product#\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    # Compute cosine similarity between two embeddings\n",
    "    res = np.tensordot(embedding1, embedding2, 1)\n",
    "    return res\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got here 1\n",
      "We got here 2\n",
      "We got here 3\n",
      "We got here 4\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter search query: \")\n",
    "print(\"We got here 1\")\n",
    "query_vector = embed_sentences([query])[0]\n",
    "print(\"We got here 2\")\n",
    "crawled_articles = [\n",
    "    documents[i][\"title\"]\n",
    "    + documents[i][\"abstract\"]\n",
    "    for i in range(len(documents))\n",
    "]\n",
    "print(\"We got here 3\")\n",
    "article_embeddings = embed_sentences(crawled_articles)\n",
    "print(\"We got here 4\")\n",
    "similarities = {\n",
    "    index: compute_similarity(query_vector, article_embedding)\n",
    "    for index, article_embedding in enumerate(article_embeddings)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 4776\n",
      "Relevance: 46.14%\n",
      "{'subject': 'q-bio', 'title': 'Sparsity-depth Tradeoff in Infinitely Wide Deep Neural Networks', 'abstract': 'We investigate how sparse neural activity affects the generalization\\nperformance of a deep Bayesian neural network at the large width limit. To this\\nend, we derive a neural network Gaussian Process (NNGP) kernel with rectified\\nlinear unit (ReLU) activation and a predetermined fraction of active neurons.\\nUsing the NNGP kernel, we observe that the sparser networks outperform the\\nnon-sparse networks at shallow depths on a variety of datasets. We validate\\nthis observation by extending the existing theory on the generalization error\\nof kernel-ridge regression.\\n'}\n",
      "\n",
      "Index: 2319\n",
      "Relevance: 45.54%\n",
      "{'subject': 'cs', 'title': 'Deep Learning and Geometric Deep Learning: an introduction for  mathematicians and physicists', 'abstract': 'In this expository paper we want to give a brief introduction, with few key\\nreferences for further reading, to the inner functioning of the new and\\nsuccessfull algorithms of Deep Learning and Geometric Deep Learning with a\\nfocus on Graph Neural Networks. We go over the key ingredients for these\\nalgorithms: the score and loss function and we explain the main steps for the\\ntraining of a model. We do not aim to give a complete and exhaustive treatment,\\nbut we isolate few concepts to give a fast introduction to the subject. We\\nprovide some appendices to complement our treatment discussing Kullback-Leibler\\ndivergence, regression, Multi-layer Perceptrons and the Universal Approximation\\nTheorem.\\n'}\n",
      "\n",
      "Index: 1225\n",
      "Relevance: 43.47%\n",
      "{'subject': 'cs', 'title': 'An array of microresonators as a Photonic Extreme Learning Machine', 'abstract': 'Machine learning technologies have found fertile ground in optics due to its\\npromising features based on speed and parallelism. Feed-forward neural networks\\nare one of the most widely used machine learning algorithms due to their\\nsimplicity and universal approximation capability. However, the typical\\ntraining procedure, where all weights are optimized, can be time and energy\\nconsuming. An alternative approach is the Extreme Learning Machine, a\\nfeed-forward neural network in which only the output weights are trained, while\\nthe internal connections are random. Here we present an experimental\\nimplementation of a photonic extreme learning machine (PELM) in an integrated\\nsilicon chip. The PELM is based on the processing of the image of the scattered\\nlight by an array of 18 gratings coupled to microresonators. Light propagation\\nin the microresonator array is a linear process while light detection by the\\nvideo camera is a nonlinear process. Training is done offline by analyzing the\\nrecorded scattered light image with a linear classifier. We provide a\\nproof-of-concept demonstration of the PELM by solving both binary and analog\\ntasks, and show how the performance depends on the number of microresonators\\nused in the readout procedure.\\n'}\n",
      "\n",
      "Index: 316\n",
      "Relevance: 41.69%\n",
      "{'subject': 'cs', 'title': 'Performance and Energy Consumption of Parallel Machine Learning  Algorithms', 'abstract': 'Machine learning models have achieved remarkable success in various\\nreal-world applications such as data science, computer vision, and natural\\nlanguage processing. However, model training in machine learning requires\\nlarge-scale data sets and multiple iterations before it can work properly.\\nParallelization of training algorithms is a common strategy to speed up the\\nprocess of training. However, many studies on model training and inference\\nfocus only on aspects of performance. Power consumption is also an important\\nmetric for any type of computation, especially high-performance applications.\\nMachine learning algorithms that can be used on low-power platforms such as\\nsensors and mobile devices have been researched, but less power optimization is\\ndone for algorithms designed for high-performance computing.\\nIn this paper, we present a C++ implementation of logistic regression and the\\ngenetic algorithm, and a Python implementation of neural networks with\\nstochastic gradient descent (SGD) algorithm on classification tasks. We will\\nshow the impact that the complexity of the model and the size of the training\\ndata have on the parallel efficiency of the algorithm in terms of both power\\nand performance. We also tested these implementations using shard-memory\\nparallelism, distributed memory parallelism, and GPU acceleration to speed up\\nmachine learning model training.\\n'}\n",
      "\n",
      "Index: 5686\n",
      "Relevance: 41.68%\n",
      "{'subject': 'eess', 'title': 'Employing Hybrid Deep Neural Networks on Dari Speech', 'abstract': 'This paper is an extension of our previous conference paper. In recent years,\\nthere has been a growing interest among researchers in developing and improving\\nspeech recognition systems to facilitate and enhance human-computer\\ninteraction. Today, Automatic Speech Recognition (ASR) systems have become\\nubiquitous, used in everything from games to translation systems, robots, and\\nmore. However, much research is still needed on speech recognition systems for\\nlow-resource languages. This article focuses on the recognition of individual\\nwords in the Dari language using the Mel-frequency cepstral coefficients\\n(MFCCs) feature extraction method and three different deep neural network\\nmodels: Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and\\nMultilayer Perceptron (MLP), as well as two hybrid models combining CNN and\\nRNN. We evaluate these models using an isolated Dari word corpus that we have\\ncreated, consisting of 1000 utterances for 20 short Dari terms. Our study\\nachieved an impressive average accuracy of 98.365%.\\n'}\n",
      "\n",
      "Index: 1233\n",
      "Relevance: 41.27%\n",
      "{'subject': 'cs', 'title': 'Input Layer Binarization with Bit-Plane Encoding', 'abstract': 'Binary Neural Networks (BNNs) use 1-bit weights and activations to\\nefficiently execute deep convolutional neural networks on edge devices.\\nNevertheless, the binarization of the first layer is conventionally excluded,\\nas it leads to a large accuracy loss. The few works addressing the first layer\\nbinarization, typically increase the number of input channels to enhance data\\nrepresentation; such data expansion raises the amount of operations needed and\\nit is feasible only on systems with enough computational resources. In this\\nwork, we present a new method to binarize the first layer using directly the\\n8-bit representation of input data; we exploit the standard bit-planes encoding\\nto extract features bit-wise (using depth-wise convolutions); after a\\nre-weighting stage, features are fused again. The resulting model is fully\\nbinarized and our first layer binarization approach is model independent. The\\nconcept is evaluated on three classification datasets (CIFAR10, SVHN and\\nCIFAR100) for different model architectures (VGG and ResNet) and, the proposed\\ntechnique outperforms state of the art methods both in accuracy and BMACs\\nreduction.\\n'}\n",
      "\n",
      "Index: 5472\n",
      "Relevance: 41.17%\n",
      "{'subject': 'stat', 'title': 'Generative AI for Bayesian Computation', 'abstract': 'Generative AI (Gen-AI) methods are developed for Bayesian Computation. Gen-AI\\nnaturally applies to Bayesian models which can be easily simulated. First, we\\ngenerate a large training dataset of data and parameters from the joint\\nprobability model. Secondly, we find a summary/sufficient statistic for\\ndimensionality reduction. Thirdly, we use a deep neural network to uncover the\\ninverse Bayes map between parameters and data. This finds the inverse posterior\\ncumulative distribution function. Bayesian computation then is equivalent to\\nhigh dimensional regression with dimensionality reduction (a.k.a feature\\nselection) and nonlnearity (a.k.a. deep learning). The main advantage of Gen-AI\\nis the ability to be density-free and hence avoids MCMC simulation of the\\nposterior. Architecture design is important and we propose deep quantile NNs as\\na general framework for inference and decision making. To illustrate our\\nmethodology, we provide three examples: a stylized synthetic example, a traffic\\nflow prediction problem and a satellite data-set. Finally, we conclude with\\ndirections for future research.\\n'}\n",
      "\n",
      "Index: 552\n",
      "Relevance: 40.74%\n",
      "{'subject': 'cs', 'title': 'Deep Learning Based Multimodal with Two-phase Training Strategy for  Daily Life Video Classification', 'abstract': 'In this paper, we present a deep learning based multimodal system for\\nclassifying daily life videos. To train the system, we propose a two-phase\\ntraining strategy. In the first training phase (Phase I), we extract the audio\\nand visual (image) data from the original video. We then train the audio data\\nand the visual data with independent deep learning based models. After the\\ntraining processes, we obtain audio embeddings and visual embeddings by\\nextracting feature maps from the pre-trained deep learning models. In the\\nsecond training phase (Phase II), we train a fusion layer to combine the\\naudio/visual embeddings and a dense layer to classify the combined embedding\\ninto target daily scenes. Our extensive experiments, which were conducted on\\nthe benchmark dataset of DCASE (IEEE AASP Challenge on Detection and\\nClassification of Acoustic Scenes and Events) 2021 Task 1B Development,\\nachieved the best classification accuracy of 80.5%, 91.8%, and 95.3% with only\\naudio data, with only visual data, both audio and visual data, respectively.\\nThe highest classification accuracy of 95.3% presents an improvement of 17.9%\\ncompared with DCASE baseline and shows very competitive to the state-of-the-art\\nsystems.\\n'}\n",
      "\n",
      "Index: 249\n",
      "Relevance: 40.64%\n",
      "{'subject': 'cs', 'title': 'Impact of Deep Learning Libraries on Online Adaptive Lightweight Time  Series Anomaly Detection', 'abstract': 'Providing online adaptive lightweight time series anomaly detection without\\nhuman intervention and domain knowledge is highly valuable. Several such\\nanomaly detection approaches have been introduced in the past years, but all of\\nthem were only implemented in one deep learning library. With the development\\nof deep learning libraries, it is unclear how different deep learning libraries\\nimpact these anomaly detection approaches since there is no such evaluation\\navailable. Randomly choosing a deep learning library to implement an anomaly\\ndetection approach might not be able to show the true performance of the\\napproach. It might also mislead users in believing one approach is better than\\nanother. Therefore, in this paper, we investigate the impact of deep learning\\nlibraries on online adaptive lightweight time series anomaly detection by\\nimplementing two state-of-the-art anomaly detection approaches in three\\nwell-known deep learning libraries and evaluating how these two approaches are\\nindividually affected by the three deep learning libraries. A series of\\nexperiments based on four real-world open-source time series datasets were\\nconducted. The results provide a good reference to select an appropriate deep\\nlearning library for online adaptive lightweight anomaly detection.\\n'}\n",
      "\n",
      "Index: 5463\n",
      "Relevance: 39.67%\n",
      "{'subject': 'stat', 'title': 'DF2M: An Explainable Deep Bayesian Nonparametric Model for  High-Dimensional Functional Time Series', 'abstract': 'In this paper, we present Deep Functional Factor Model (DF2M), a Bayesian\\nnonparametric model for analyzing high-dimensional functional time series. The\\nDF2M makes use of the Indian Buffet Process and the multi-task Gaussian Process\\nwith a deep kernel function to capture non-Markovian and nonlinear temporal\\ndynamics. Unlike many black-box deep learning models, the DF2M provides an\\nexplainable way to use neural networks by constructing a factor model and\\nincorporating deep neural networks within the kernel function. Additionally, we\\ndevelop a computationally efficient variational inference algorithm for\\ninferring the DF2M. Empirical results from four real-world datasets demonstrate\\nthat the DF2M offers better explainability and superior predictive accuracy\\ncompared to conventional deep learning models for high-dimensional functional\\ntime series.\\n'}\n",
      "\n",
      "Index: 607\n",
      "Relevance: 39.57%\n",
      "{'subject': 'cs', 'title': 'Accelerating Neural Self-Improvement via Bootstrapping', 'abstract': 'Few-shot learning with sequence-processing neural networks (NNs) has recently\\nattracted a new wave of attention in the context of large language models. In\\nthe standard N-way K-shot learning setting, an NN is explicitly optimised to\\nlearn to classify unlabelled inputs by observing a sequence of NK labelled\\nexamples. This pressures the NN to learn a learning algorithm that achieves\\noptimal performance, given the limited number of training examples. Here we\\nstudy an auxiliary loss that encourages further acceleration of few-shot\\nlearning, by applying recently proposed bootstrapped meta-learning to NN\\nfew-shot learners: we optimise the K-shot learner to match its own performance\\nachievable by observing more than NK examples, using only NK examples.\\nPromising results are obtained on the standard Mini-ImageNet dataset. Our code\\nis public.\\n'}\n",
      "\n",
      "Index: 1629\n",
      "Relevance: 39.55%\n",
      "{'subject': 'cs', 'title': 'Decentralised Semi-supervised Onboard Learning for Scene Classification  in Low-Earth Orbit', 'abstract': 'Onboard machine learning on the latest satellite hardware offers the\\npotential for significant savings in communication and operational costs. We\\nshowcase the training of a machine learning model on a satellite constellation\\nfor scene classification using semi-supervised learning while accounting for\\noperational constraints such as temperature and limited power budgets based on\\nsatellite processor benchmarks of the neural network. We evaluate mission\\nscenarios employing both decentralised and federated learning approaches. All\\nscenarios achieve convergence to high accuracy (around 91% on EuroSAT RGB\\ndataset) within a one-day mission timeframe.\\n'}\n",
      "\n",
      "Index: 656\n",
      "Relevance: 39.37%\n",
      "{'subject': 'cs', 'title': 'Hamming Similarity and Graph Laplacians for Class Partitioning and  Adversarial Image Detection', 'abstract': 'Researchers typically investigate neural network representations by examining\\nactivation outputs for one or more layers of a network. Here, we investigate\\nthe potential for ReLU activation patterns (encoded as bit vectors) to aid in\\nunderstanding and interpreting the behavior of neural networks. We utilize\\nRepresentational Dissimilarity Matrices (RDMs) to investigate the coherence of\\ndata within the embedding spaces of a deep neural network. From each layer of a\\nnetwork, we extract and utilize bit vectors to construct similarity scores\\nbetween images. From these similarity scores, we build a similarity matrix for\\na collection of images drawn from 2 classes. We then apply Fiedler partitioning\\nto the associated Laplacian matrix to separate the classes. Our results\\nindicate, through bit vector representations, that the network continues to\\nrefine class detectability with the last ReLU layer achieving better than 95\\\\%\\nseparation accuracy. Additionally, we demonstrate that bit vectors aid in\\nadversarial image detection, again achieving over 95\\\\% accuracy in separating\\nadversarial and non-adversarial images using a simple classifier.\\n'}\n",
      "\n",
      "Index: 3148\n",
      "Relevance: 39.15%\n",
      "{'subject': 'physics', 'title': 'NAS-PINN: Neural architecture search-guided physics-informed neural  network for solving PDEs', 'abstract': 'Physics-informed neural network (PINN) has been a prevalent framework for\\nsolving PDEs since proposed. By incorporating the physical information into the\\nneural network through loss functions, it can predict solutions to PDEs in an\\nunsupervised manner. However, the design of the neural network structure\\nbasically relies on prior knowledge and experience, which has caused great\\ntrouble and high computational overhead. Therefore, we propose a neural\\narchitecture search-guided method, namely NAS-PINN, to automatically search the\\noptimum neural architecture for solving certain PDEs. By relaxing the search\\nspace into a continuous one and utilizing masks to realize the addition of\\ntensors in different shapes, NAS-PINN can be trained through a bi-level\\noptimization, where the inner loop optimizes the weights and bias of neural\\nnetworks and the outer loop the architecture parameters. We verify the ability\\nof NAS-PINN by several numerical experiments including Poisson, Burgers, and\\nAdvection equations. The characteristics of effective neural architectures for\\nsolving different PDEs are summarized, which can be used to guide the design of\\nneural networks in PINN. It is found that more hidden layers do not necessarily\\nmean better performance and sometimes can be harmful. Especially for Poisson\\nand Advection, a shallow neural network with more neurons is more appropriate\\nin PINNs. It is also indicated that for complex problems, neural networks with\\nresidual connection can improve the performance of PINNs.\\n'}\n",
      "\n",
      "Index: 4822\n",
      "Relevance: 38.86%\n",
      "{'subject': 'q-bio', 'title': 'Are Deep Neural Networks Adequate Behavioural Models of Human Visual  Perception?', 'abstract': 'Deep neural networks (DNNs) are machine learning algorithms that have\\nrevolutionised computer vision due to their remarkable successes in tasks like\\nobject classification and segmentation. The success of DNNs as computer vision\\nalgorithms has led to the suggestion that DNNs may also be good models of human\\nvisual perception. We here review evidence regarding current DNNs as adequate\\nbehavioural models of human core object recognition. To this end, we argue that\\nit is important to distinguish between statistical tools and computational\\nmodels, and to understand model quality as a multidimensional concept where\\nclarity about modelling goals is key. Reviewing a large number of\\npsychophysical and computational explorations of core object recognition\\nperformance in humans and DNNs, we argue that DNNs are highly valuable\\nscientific tools but that as of today DNNs should only be regarded as promising\\n-- but not yet adequate -- computational models of human core object\\nrecognition behaviour. On the way we dispel a number of myths surrounding DNNs\\nin vision science.\\n'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similarities_dup = similarities.copy()\n",
    "results_limit = 15\n",
    "top_results = []\n",
    "\n",
    "for i in range(results_limit):\n",
    "    max_similarity_index = max(similarities_dup.keys(), key=similarities_dup.__getitem__)\n",
    "    top_results.append(max_similarity_index)\n",
    "    del similarities_dup[max_similarity_index]\n",
    "\n",
    "\n",
    "for result in top_results:\n",
    "    print(f\"Index: {result}\\n\"\n",
    "          f\"Relevance: {similarities[result]*100:.2f}%\\n\"\n",
    "          f\"{documents[result]}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
